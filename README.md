# Big Data Analytics with Apache Spark

This project demonstrates how to use Apache Spark for distributed data analysis and processing using a public database. It walks through key Spark components such as Spark SQL, DataFrame APIs, and storage optimizations, focusing on real-world data manipulation, transformations, and performance strategies.<br><br>

**Technologies Used:**<br>
PySpark<br>
SparkSQL<br>
Python<br>
Google Colaboratory Notebook<br><br>

**Objective:**<br>
Explore and apply Sparkâ€™s capabilities to perform scalable data processing on a test dataset.<br><br>

**Project Steps:**<br>
1- Introduction to Spark and Libraries<br>
2- Data Loading<br>
3- Data Manipulation<br>
4- Data Analysis<br>
5- Spark SQL<br>
6- Data Cleaning and Transformation<br>
7- Aggregations and Joins<br>
8- Data Storage and Partitioning
